{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation et imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pandas in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from Pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->Pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Matplotlib in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from Matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from Matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->Matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Scikit-learn in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Numpy in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.25.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import et données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>descr_cat_veh</th>\n",
       "      <th>descr_agglo</th>\n",
       "      <th>place</th>\n",
       "      <th>descr_dispo_secu</th>\n",
       "      <th>descr_grav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7266</td>\n",
       "      <td>48.8925</td>\n",
       "      <td>2.344400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10329</td>\n",
       "      <td>48.6000</td>\n",
       "      <td>2.116670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27098</td>\n",
       "      <td>47.2167</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4887</td>\n",
       "      <td>48.5333</td>\n",
       "      <td>2.666670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6206</td>\n",
       "      <td>50.7167</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>23081</td>\n",
       "      <td>44.9500</td>\n",
       "      <td>5.716670</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>120</td>\n",
       "      <td>47.2000</td>\n",
       "      <td>-1.566670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>827</td>\n",
       "      <td>48.1333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>18619</td>\n",
       "      <td>47.2000</td>\n",
       "      <td>-0.283333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>2515</td>\n",
       "      <td>47.2167</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7498 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  latitude  longitude  descr_cat_veh  descr_agglo  place  \\\n",
       "0      7266   48.8925   2.344400              0            0      0   \n",
       "1     10329   48.6000   2.116670              1            1      0   \n",
       "2     27098   47.2167  -1.550000              0            0      0   \n",
       "3      4887   48.5333   2.666670              0            1      2   \n",
       "4      6206   50.7167   3.150000              0            0      0   \n",
       "...     ...       ...        ...            ...          ...    ...   \n",
       "7493  23081   44.9500   5.716670              2            1      0   \n",
       "7494    120   47.2000  -1.566670              0            0      0   \n",
       "7495    827   48.1333  -1.000000              0            1      0   \n",
       "7496  18619   47.2000  -0.283333              0            0      0   \n",
       "7497   2515   47.2167  -1.550000              0            0      9   \n",
       "\n",
       "      descr_dispo_secu  descr_grav  \n",
       "0                   14           0  \n",
       "1                   14           0  \n",
       "2                    7           0  \n",
       "3                   14           0  \n",
       "4                    8           0  \n",
       "...                ...         ...  \n",
       "7493                11           3  \n",
       "7494                14           3  \n",
       "7495                14           3  \n",
       "7496                14           3  \n",
       "7497                 0           3  \n",
       "\n",
       "[7498 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../dfClean.csv\")\n",
    "\n",
    "counts = data['descr_grav'].value_counts()\n",
    "\n",
    "total_0 = counts[0]/len(data)\n",
    "total_1 = counts[1]/len(data)\n",
    "total_2 = counts[2]/len(data)\n",
    "total_3 = counts[3]/len(data)\n",
    "\n",
    "Proportion_0 = data[data['descr_grav'] == 0].sample(n=int(7500*total_0))\n",
    "Proportion_1 = data[data['descr_grav'] == 1].sample(n=int(7500*total_1))\n",
    "Proportion_2 = data[data['descr_grav'] == 2].sample(n=int(7500*total_2))\n",
    "Proportion_3 = data[data['descr_grav'] == 3].sample(n=int(7500*total_3))\n",
    "\n",
    "data_reduit = pd.concat([Proportion_0,Proportion_1, Proportion_2, Proportion_3])\n",
    "data_reduit = data_reduit.reset_index(drop=True)\n",
    "print(len(data_reduit))\n",
    "display(data_reduit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Répartition des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition holdout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout(dataframe, colonne_predict, num_rep, train_s, test_s ):\n",
    "        liste_data_train_test = []\n",
    "        liste_data = []\n",
    "        clean_data = dataframe.drop(colonne_predict, axis = 1)\n",
    "        y = dataframe[colonne_predict]\n",
    "        for i in range(num_rep):\n",
    "                X_train, X_test, y_train, y_test = train_test_split(clean_data,y, train_size= train_s, test_size = test_s)\n",
    "                X_train = X_train.reset_index(drop=True)\n",
    "                y_train = y_train.reset_index(drop=True)\n",
    "                X_test = X_test.reset_index(drop=True)\n",
    "                y_test = y_test.reset_index(drop=True)\n",
    "                liste_data_train_test.append([X_train, X_test, y_train, y_test])\n",
    "        return liste_data_train_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Répartition Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaveoneout(dataframe, colonne_predict,k):\n",
    "    liste_y_pred = []\n",
    "    liste_y_test = []\n",
    "    X = dataframe.drop(colonne_predict, axis = 1) \n",
    "    y = dataframe[colonne_predict]\n",
    "    LOO = LeaveOneOut()\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    for train_index, test_index in (LOO.split(X)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        liste_y_pred.append(y_pred)\n",
    "        liste_y_test.append(y_test)\n",
    "        \n",
    "    return liste_y_pred, liste_y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification avec KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de classification knn\n",
    "def KnnClassification_distance_euclidienne(ligne,y_train,df,k):\n",
    "    dictList = [None] * len(df)\n",
    "    liste_y_pred = []\n",
    "    for index, row in df.iterrows():\n",
    "        dictList[index] = np.linalg.norm(ligne - row) #calcul de la distance euclidienne\n",
    "    \n",
    "    sorted_values = sorted(enumerate(dictList), key=lambda x: x[1])[:k]\n",
    "    for index,value in sorted_values:\n",
    "        #firstk.append([df.loc[index]])\n",
    "        liste_y_pred.append(y_train[index])\n",
    "    \n",
    "    y_pred = np.bincount(liste_y_pred).argmax()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de classification knn\n",
    "def KnnClassification_distance_manhattan(ligne, y_train, df, k):\n",
    "    dictList = [None] * len(df)\n",
    "    liste_y_pred = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        dictList[index] = np.sum(np.abs(ligne - row))  # Calcul de la distance de Manhattan\n",
    "    \n",
    "    sorted_values = sorted(enumerate(dictList), key=lambda x: x[1])[:k]\n",
    "    \n",
    "    for index, value in sorted_values:\n",
    "        liste_y_pred.append(y_train[index])\n",
    "    \n",
    "    y_pred = np.bincount(liste_y_pred).argmax()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnnClassification_distance_sup_norme(ligne, y_train, df, k):\n",
    "    dictList = [None] * len(df)\n",
    "    liste_y_pred = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        dictList[index] = np.max(np.abs(ligne - row))  # Calcul de la distance de la norme supérieure\n",
    "    \n",
    "    sorted_values = sorted(enumerate(dictList), key=lambda x: x[1])[:k]\n",
    "    \n",
    "    for index, value in sorted_values:\n",
    "        liste_y_pred.append(y_train[index])\n",
    "    \n",
    "    y_pred = np.bincount(liste_y_pred).argmax()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction holdout sklearn\n",
    "def  KnnClassification_sk_learn(liste_data):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    liste_y_pred_holdout_sk = []\n",
    "    liste_y_test_holdout_sk = []\n",
    "    for i in range(len(liste_data)):\n",
    "        X_train = liste_data[i][0]\n",
    "        X_test = liste_data[i][1]\n",
    "        y_test = liste_data[i][3]\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        liste_y_pred_holdout_sk.append(y_pred)\n",
    "        liste_y_test_holdout_sk.append(y_test)\n",
    "    return liste_y_pred_holdout_sk, liste_y_test_holdout_sk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Répartition leave One Out\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_LOO_5, y_test_LOO_5 \u001b[39m=\u001b[39m leaveoneout(data_reduit, \u001b[39m\"\u001b[39;49m\u001b[39mdescr_grav\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m y_pred_LOO_7, y_test_LOO_7 \u001b[39m=\u001b[39m leaveoneout(data_reduit, \u001b[39m\"\u001b[39m\u001b[39mdescr_grav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m7\u001b[39m)\n\u001b[0;32m      4\u001b[0m y_pred_LOO_10, y_test_LOO_10 \u001b[39m=\u001b[39m leaveoneout(data_reduit, \u001b[39m\"\u001b[39m\u001b[39mdescr_grav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mleaveoneout\u001b[1;34m(dataframe, colonne_predict, k)\u001b[0m\n\u001b[0;32m     11\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39miloc[train_index], y\u001b[39m.\u001b[39miloc[test_index]\n\u001b[0;32m     12\u001b[0m knn\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 13\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     14\u001b[0m liste_y_pred\u001b[39m.\u001b[39mappend(y_pred)\n\u001b[0;32m     15\u001b[0m liste_y_test\u001b[39m.\u001b[39mappend(y_test)\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:879\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    873\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    874\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    875\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    876\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor set algorithm=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    877\u001b[0m             \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method\n\u001b[0;32m    878\u001b[0m         )\n\u001b[1;32m--> 879\u001b[0m     chunked_results \u001b[39m=\u001b[39m Parallel(n_jobs, prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[0;32m    880\u001b[0m         delayed(_tree_query_parallel_helper)(\n\u001b[0;32m    881\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tree, X[s], n_neighbors, return_distance\n\u001b[0;32m    882\u001b[0m         )\n\u001b[0;32m    883\u001b[0m         \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m gen_even_slices(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], n_jobs)\n\u001b[0;32m    884\u001b[0m     )\n\u001b[0;32m    885\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minternal: _fit_method not recognized\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ewann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:685\u001b[0m, in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_tree_query_parallel_helper\u001b[39m(tree, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \n\u001b[0;32m    682\u001b[0m \u001b[39m    The Cython method tree.query is not directly picklable by cloudpickle\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[39m    under PyPy.\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 685\u001b[0m     \u001b[39mreturn\u001b[39;00m tree\u001b[39m.\u001b[39;49mquery(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Répartition leave One Out\n",
    "y_pred_LOO_5, y_test_LOO_5 = leaveoneout(data_reduit, \"descr_grav\", 5)\n",
    "y_pred_LOO_7, y_test_LOO_7 = leaveoneout(data_reduit, \"descr_grav\", 7)\n",
    "y_pred_LOO_10, y_test_LOO_10 = leaveoneout(data_reduit, \"descr_grav\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_LOO_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Score répartition leave One Out\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy_LOO_5 \u001b[39m=\u001b[39m accuracy_score(y_test_LOO_5, y_pred_LOO_5)\n\u001b[0;32m      3\u001b[0m accuracy_LOO_7 \u001b[39m=\u001b[39m accuracy_score(y_test_LOO_7, y_pred_LOO_7)\n\u001b[0;32m      4\u001b[0m accuracy_LOO_10 \u001b[39m=\u001b[39m accuracy_score(y_test_LOO_10, y_pred_LOO_10)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_LOO_5' is not defined"
     ]
    }
   ],
   "source": [
    "# Score répartition leave One Out\n",
    "accuracy_LOO_5 = accuracy_score(y_test_LOO_5, y_pred_LOO_5)\n",
    "accuracy_LOO_7 = accuracy_score(y_test_LOO_7, y_pred_LOO_7)\n",
    "accuracy_LOO_10 = accuracy_score(y_test_LOO_10, y_pred_LOO_10)\n",
    "\n",
    "print(accuracy_LOO_5*100)\n",
    "print(accuracy_LOO_7*100)\n",
    "print(accuracy_LOO_10*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m X_train_0 \u001b[39m=\u001b[39m liste_data_holdout[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m y_test_0 \u001b[39m=\u001b[39m  liste_data_holdout[\u001b[39m0\u001b[39m][\u001b[39m3\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_test)):\n\u001b[0;32m     19\u001b[0m     y_pred_holdout_sup_norme \u001b[39m=\u001b[39m KnnClassification_distance_sup_norme(X_test\u001b[39m.\u001b[39mloc[i], y_train, X_train, \u001b[39m5\u001b[39m)\n\u001b[0;32m     20\u001b[0m     liste_y_pred_holdout_LOO_sup_norme\u001b[39m.\u001b[39mappend(y_pred_holdout_sup_norme)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Répartition hold out\n",
    "liste_data_holdout = []\n",
    "#data_test = data.drop(columns=[\"latitude\", \"longitude\"])\n",
    "data_test = data_reduit\n",
    "liste_data_holdout  = holdout(data_reduit,\"descr_grav\", 5, 0.8, 0.2)\n",
    "\n",
    "# Prediction holdout from scratch\n",
    "liste_y_pred_holdout_LOO_euclidienne = []\n",
    "liste_y_pred_holdout_LOO_manhattan = []\n",
    "liste_y_pred_holdout_LOO_sup_norme = []\n",
    "\n",
    "\n",
    "X_test_0 = liste_data_holdout[0][1]\n",
    "y_train_0  = liste_data_holdout[0][2]\n",
    "X_train_0 = liste_data_holdout[0][0]\n",
    "y_test_0 =  liste_data_holdout[0][3]\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_holdout_sup_norme = KnnClassification_distance_sup_norme(X_test.loc[i], y_train, X_train, 5)\n",
    "    liste_y_pred_holdout_LOO_sup_norme.append(y_pred_holdout_sup_norme)\n",
    "    y_pred_holdout_euclidienne = KnnClassification_distance_euclidienne(X_test.loc[i], y_train, X_train, 5)\n",
    "    liste_y_pred_holdout_LOO_euclidienne.append(y_pred_holdout_euclidienne)\n",
    "    y_pred_holdout_manhattan = KnnClassification_distance_manhattan(X_test.loc[i], y_train, X_train, 5)\n",
    "    liste_y_pred_holdout_LOO_manhattan.append(y_pred_holdout_manhattan)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_holdout_sup_norme = KnnClassification_distance_sup_norme(X_test.loc[i], y_train, X_train, 7)\n",
    "    liste_y_pred_holdout_LOO_sup_norme.append(y_pred_holdout_sup_norme)\n",
    "    y_pred_holdout_euclidienne = KnnClassification_distance_euclidienne(X_test.loc[i], y_train, X_train, 7)\n",
    "    liste_y_pred_holdout_LOO_euclidienne.append(y_pred_holdout_euclidienne)\n",
    "    y_pred_holdout_manhattan = KnnClassification_distance_manhattan(X_test.loc[i], y_train, X_train, 7)\n",
    "    liste_y_pred_holdout_LOO_manhattan.append(y_pred_holdout_manhattan)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_holdout_sup_norme = KnnClassification_distance_sup_norme(X_test.loc[i], y_train, X_train, 10)\n",
    "    liste_y_pred_holdout_LOO_sup_norme.append(y_pred_holdout_sup_norme)\n",
    "    y_pred_holdout_euclidienne = KnnClassification_distance_euclidienne(X_test.loc[i], y_train, X_train, 10)\n",
    "    liste_y_pred_holdout_LOO_euclidienne.append(y_pred_holdout_euclidienne)\n",
    "    y_pred_holdout_manhattan = KnnClassification_distance_manhattan(X_test.loc[i], y_train, X_train, 10)\n",
    "    liste_y_pred_holdout_LOO_manhattan.append(y_pred_holdout_manhattan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (149622622.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Score euclidienne:\" accuracy_holdout_euclidienne*100)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Score répartition leave One Out\n",
    "accuracy_holdout_euclidienne = accuracy_score(y_test_0, liste_y_pred_holdout_LOO_euclidienne)\n",
    "accuracy_holdout_manhattan = accuracy_score(y_test_0, liste_y_pred_holdout_LOO_manhattan)\n",
    "accuracy_holdout_sup_norme = accuracy_score(y_test_0, liste_y_pred_holdout_LOO_sup_norme)\n",
    "\n",
    "print(\"Score euclidienne:\" accuracy_holdout_euclidienne*100)\n",
    "print(\"Score manhattan:\" accuracy_holdout_manhattan*100)\n",
    "print(\"Score sup norme:\" accuracy_holdout_sup_norme*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score prediction holdout scikit learn\n",
    "#for i in range(len(liste_y_pred_holdout_sk)):\n",
    "liste_y_pred_holdout_sk, liste_y_test_holdout_sk = KnnClassification_sk_learn(liste_data_holdout)\n",
    "accuracy_holdout_sk = accuracy_score(liste_y_test_holdout_sk, liste_y_pred_holdout_sk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification avec trois algo \"haut niveau\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## support vector machine (SVM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"../dfClean.csv\")\n",
    "\n",
    "\n",
    "# Step 2: Sample the specified percentage of rows\n",
    "df = df.sample(frac=0.06, random_state=42)\n",
    "\n",
    "# Step 3: Store the sampled portion in a new DataFrame\n",
    "df.reset_index(drop=True, inplace=True)  # Reset index if needed\n",
    "\n",
    "\n",
    "# Step 1: Select feature columns (X) and target column (y)\n",
    "feature_columns = df.columns.drop('descr_grav')\n",
    "target_column = 'descr_grav'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1,10],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.1, 0.5, 1]\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Create an SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Step 4: Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 0.5, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 0.5, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.1, 0.5, 1],\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 5: Fit the GridSearchCV object\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Score: 0.4054902922542408\n",
      "[[372   0   0   0]\n",
      " [307   0   0   0]\n",
      " [167   0   0   0]\n",
      " [ 29   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Retrieve the best parameters and best score\n",
    "best_params_svm = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", best_params_svm)\n",
    "print(\"Best Score:\", best_score)\n",
    "ypred = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,ypred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=0.1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 7: Train a new SVM model with the best parameters\n",
    "best_svm = SVC(**best_params_svm)\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/modelSVC.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_svm,\"../models/modelSVC.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42514285714285716\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the model on the test data or perform further analysis\n",
    "accuracy = best_svm.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Step 1: Select feature columns (X) and target column (y)\n",
    "\n",
    "df = pd.read_csv(\"../dfClean.csv\")\n",
    "df = df.sample(frac=0.06, random_state=16)\n",
    "\n",
    "# Step 3: Store the sampled portion in a new DataFrame\n",
    "df.reset_index(drop=True, inplace=True)  # Reset index if needed\n",
    "\n",
    "\n",
    "feature_columns = df.columns.drop('descr_grav')\n",
    "target_column = 'descr_grav'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "\n",
    "# Step 3: Define the RandomForest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Step 4: Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Step 5: Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(rf, param_grid, scoring='accuracy')\n",
    "\n",
    "# Step 6: Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Step 8: Train the RandomForest model with the best parameters\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Evaluate the model on the testing data\n",
    "accuracy = best_rf.score(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/modelRF.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_rf,\"../models/modelRF.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best Score: 0.6185330063355814\n",
      "Accuracy: 0.6\n",
      "[[296  56  17   0]\n",
      " [111 160  36   0]\n",
      " [ 43  69  57   2]\n",
      " [  8   8  12   0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters, best score, and accuracy\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "best_model = grid_search.best_estimator_\n",
    "ypred = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,ypred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultilayerPerceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Étape 1: Sélectionner les colonnes des caractéristiques (X) et la colonne cible (y)\n",
    "\n",
    "df = pd.read_csv(\"../dfClean.csv\")\n",
    "df = df.sample(frac=0.06, random_state=16)\n",
    "\n",
    "# Step 3: Store the sampled portion in a new DataFrame\n",
    "df.reset_index(drop=True, inplace=True)  # Reset index if needed\n",
    "\n",
    "\n",
    "\n",
    "feature_columns = df.columns.drop('descr_grav')\n",
    "target_column = 'descr_grav'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Étape 2: Fractionner les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "\n",
    "# Étape 3: Définir le classifieur MLP\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Étape 4: Définir la grille de paramètres pour GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (200,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "# Étape 5: Créer un objet GridSearchCV\n",
    "grid_search = GridSearchCV(mlp, param_grid, scoring='accuracy')\n",
    "\n",
    "# Étape 6: Adapter l'objet GridSearchCV aux données d'entraînement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Étape 7: Obtenir les meilleurs paramètres et le meilleur score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Étape 8: Entraîner le modèle MLP avec les meilleurs paramètres\n",
    "best_mlp = MLPClassifier(**best_params)\n",
    "best_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Étape 9: Évaluer le modèle sur les données de test\n",
    "accuracy = best_mlp.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/modelMLP.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_mlp,\"../models/modelMLP.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
      "Best Score: 0.4215054159002657\n",
      "Accuracy: 0.4205714285714286\n",
      "[[369   0   0   0]\n",
      " [307   0   0   0]\n",
      " [171   0   0   0]\n",
      " [ 28   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters, best score, and accuracy\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "best_model = grid_search.best_estimator_\n",
    "ypred = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,ypred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.4228571428571429\n",
      "RandomForestClassifier 0.5874285714285714\n",
      "SVC 0.4217142857142857\n",
      "VotingClassifier 0.4217142857142857\n"
     ]
    }
   ],
   "source": [
    "model_1 = joblib.load(\"../models/modelMLP.pkl\")\n",
    "model_2 = joblib.load(\"../models/modelRF.pkl\")\n",
    "model_3 = joblib.load(\"../models/modelSVC.pkl\")\n",
    "\n",
    "model_4 = VotingClassifier([('MLP',model_1),\n",
    "     ('RandFor',model_2),\n",
    "     ('SVC',model_3)],\n",
    "     voting='hard')\n",
    "\n",
    "for model in (model_1,model_2,model_3,model_4):\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.__class__.__name__,model.score(X_test,y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faire un tableau + plot bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/modelVote.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_mlp,\"../models/modelVote.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test code philip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(objet, X, Y):\n",
    "    #calcul taux de classification\n",
    "    taux_classification = cross_val_score(objet, X, Y, scoring='accuracy')\n",
    "    #Moyenne taux de classification\n",
    "    moyenne_taux_classification = np.mean(taux_classification)\n",
    "    #prédiction \n",
    "    Y_pred = cross_val_predict(objet, X, Y)\n",
    "    #Calcul du score (taux d'apprentissage)\n",
    "    accuracy = accuracy_score(Y, Y_pred)\n",
    "    # Matrice de confusion à partir des classes réelle et celles prédites\n",
    "    matrice_confusion = ConfusionMatrixDisplay.from_predictions(Y, Y_pred, normalize=\"true\",  values_format=\".0%\") #résultat en pourcentage\n",
    "    # Précision du modèle\n",
    "    precision = precision_score(Y, Y_pred, average='weighted')\n",
    "    # Rappel du modèle\n",
    "    rappel = recall_score(Y, Y_pred, average='weighted')\n",
    "\n",
    "    return taux_classification, moyenne_taux_classification, Y_pred, accuracy, matrice_confusion, precision, rappel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dict = {\n",
    "  'name' : 'caca',\n",
    "  'oui' : 'non'\n",
    " }\n",
    "\n",
    "jsonvar = json.dump('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_1 \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m../models/modelMLP.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(evaluation(model_1,X_test,y_test))\n",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m, in \u001b[0;36mevaluation\u001b[1;34m(objet, X, Y)\u001b[0m\n\u001b[0;32m      7\u001b[0m Y_pred \u001b[39m=\u001b[39m cross_val_predict(objet, X, Y)\n\u001b[0;32m      8\u001b[0m \u001b[39m#Calcul du score (taux d'apprentissage)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(Y, Y_pred)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Matrice de confusion à partir des classes réelle et celles prédites\u001b[39;00m\n\u001b[0;32m     11\u001b[0m matrice_confusion \u001b[39m=\u001b[39m ConfusionMatrixDisplay\u001b[39m.\u001b[39mfrom_predictions(Y, Y_pred, normalize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m,  values_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.0\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#résultat en pourcentage\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "model_1 = joblib.load(\"../models/modelMLP.pkl\")\n",
    "print(evaluation(model_1,X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
