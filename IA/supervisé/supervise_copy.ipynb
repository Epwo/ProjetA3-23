{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation et imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pandas in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from Pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Pandas) (1.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->Pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Matplotlib in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from Matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Matplotlib) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from Matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ewann\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->Matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Scikit-learn in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Scikit-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Numpy in c:\\users\\ewann\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import et donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>descr_cat_veh</th>\n",
       "      <th>descr_agglo</th>\n",
       "      <th>place</th>\n",
       "      <th>descr_dispo_secu</th>\n",
       "      <th>descr_grav</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14026</td>\n",
       "      <td>45.6333</td>\n",
       "      <td>-1.083330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6248</td>\n",
       "      <td>48.8584</td>\n",
       "      <td>2.379500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19854</td>\n",
       "      <td>48.6000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9077</td>\n",
       "      <td>43.6000</td>\n",
       "      <td>1.433330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7068</td>\n",
       "      <td>50.0500</td>\n",
       "      <td>1.416670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>13198</td>\n",
       "      <td>49.3170</td>\n",
       "      <td>0.269444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>28397</td>\n",
       "      <td>48.3000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>8130</td>\n",
       "      <td>45.8167</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>22952</td>\n",
       "      <td>48.2000</td>\n",
       "      <td>4.133330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>8764</td>\n",
       "      <td>46.1167</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7498 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  latitude  longitude  descr_cat_veh  descr_agglo  place  \\\n",
       "0     14026   45.6333  -1.083330              0            0      0   \n",
       "1      6248   48.8584   2.379500              0            0      0   \n",
       "2     19854   48.6000   7.600000              1            1      0   \n",
       "3      9077   43.6000   1.433330              0            0      0   \n",
       "4      7068   50.0500   1.416670              0            0      0   \n",
       "...     ...       ...        ...            ...          ...    ...   \n",
       "7493  13198   49.3170   0.269444              0            1      0   \n",
       "7494  28397   48.3000   4.050000              0            1      0   \n",
       "7495   8130   45.8167  -0.350000              0            1      0   \n",
       "7496  22952   48.2000   4.133330              0            1      0   \n",
       "7497   8764   46.1167  -0.266667              0            1      0   \n",
       "\n",
       "      descr_dispo_secu  descr_grav  \n",
       "0                   14           0  \n",
       "1                   14           0  \n",
       "2                   14           0  \n",
       "3                   14           0  \n",
       "4                   14           0  \n",
       "...                ...         ...  \n",
       "7493                14           3  \n",
       "7494                14           3  \n",
       "7495                14           3  \n",
       "7496                14           3  \n",
       "7497                14           3  \n",
       "\n",
       "[7498 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../dfClean.csv\")\n",
    "\n",
    "counts = data['descr_grav'].value_counts()\n",
    "\n",
    "total_0 = counts[0]/len(data)\n",
    "total_1 = counts[1]/len(data)\n",
    "total_2 = counts[2]/len(data)\n",
    "total_3 = counts[3]/len(data)\n",
    "\n",
    "Proportion_0 = data[data['descr_grav'] == 0].sample(n=int(7500*total_0))\n",
    "Proportion_1 = data[data['descr_grav'] == 1].sample(n=int(7500*total_1))\n",
    "Proportion_2 = data[data['descr_grav'] == 2].sample(n=int(7500*total_2))\n",
    "Proportion_3 = data[data['descr_grav'] == 3].sample(n=int(7500*total_3))\n",
    "\n",
    "data_reduit = pd.concat([Proportion_0,Proportion_1, Proportion_2, Proportion_3])\n",
    "data_reduit = data_reduit.reset_index(drop=True)\n",
    "print(len(data_reduit))\n",
    "display(data_reduit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R√©partition des donn√©es"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©partition holdout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout(dataframe, colonne_predict, num_rep, train_s, test_s ):\n",
    "        liste_data_train_test = []\n",
    "        liste_data = []\n",
    "        clean_data = dataframe.drop(colonne_predict, axis = 1)\n",
    "        y = dataframe[colonne_predict]\n",
    "        for i in range(num_rep):\n",
    "                X_train, X_test, y_train, y_test = train_test_split(clean_data,y, train_size= train_s, test_size = test_s)\n",
    "                X_train = X_train.reset_index(drop=True)\n",
    "                y_train = y_train.reset_index(drop=True)\n",
    "                X_test = X_test.reset_index(drop=True)\n",
    "                y_test = y_test.reset_index(drop=True)\n",
    "                liste_data_train_test.append([X_train, X_test, y_train, y_test])\n",
    "        return liste_data_train_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©partition Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaveoneout(dataframe, colonne_predict,k):\n",
    "    liste_y_pred = []\n",
    "    liste_y_test = []\n",
    "    X = dataframe.drop(colonne_predict, axis = 1) \n",
    "    y = dataframe[colonne_predict]\n",
    "    LOO = LeaveOneOut()\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    for train_index, test_index in (LOO.split(X)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        liste_y_pred.append(y_pred)\n",
    "        liste_y_test.append(y_test)\n",
    "        \n",
    "    return liste_y_pred, liste_y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification avec KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de classification knn\n",
    "def KnnClassification_distance_euclidienne(ligne,y_train,df,k):\n",
    "    dictList = [None] * len(df)\n",
    "    liste_y_pred = []\n",
    "    for index, row in df.iterrows():\n",
    "        dictList[index] = np.linalg.norm(ligne - row) #calcul de la distance euclidienne\n",
    "    \n",
    "    sorted_values = sorted(enumerate(dictList), key=lambda x: x[1])[:k]\n",
    "    for index,value in sorted_values:\n",
    "        #firstk.append([df.loc[index]])\n",
    "        liste_y_pred.append(y_train[index])\n",
    "    \n",
    "    y_pred = np.bincount(liste_y_pred).argmax()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de classification knn\n",
    "def KnnClassification_distance_manhattan(ligne, y_train, df, k):\n",
    "    dictList = [None] * len(df)\n",
    "    liste_y_pred = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        dictList[index] = np.sum(np.abs(ligne - row))  # Calcul de la distance de Manhattan\n",
    "    \n",
    "    sorted_values = sorted(enumerate(dictList), key=lambda x: x[1])[:k]\n",
    "    \n",
    "    for index, value in sorted_values:\n",
    "        liste_y_pred.append(y_train[index])\n",
    "    \n",
    "    y_pred = np.bincount(liste_y_pred).argmax()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnnClassification_distance_sup_norme(ligne, y_train, df, k):\n",
    "    dictList = [None] * len(df)\n",
    "    liste_y_pred = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        dictList[index] = np.max(np.abs(ligne - row))  # Calcul de la distance de la norme sup√©rieure\n",
    "    \n",
    "    sorted_values = sorted(enumerate(dictList), key=lambda x: x[1])[:k]\n",
    "    \n",
    "    for index, value in sorted_values:\n",
    "        liste_y_pred.append(y_train[index])\n",
    "    \n",
    "    y_pred = np.bincount(liste_y_pred).argmax()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction holdout sklearn\n",
    "def  KnnClassification_sk_learn(liste_data):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    liste_y_pred_holdout_sk = []\n",
    "    liste_y_test_holdout_sk = []\n",
    "    for i in range(len(liste_data)):\n",
    "        X_train = liste_data[i][0]\n",
    "        X_test = liste_data[i][1]\n",
    "        y_test = liste_data[i][3]\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        liste_y_pred_holdout_sk.append(y_pred)\n",
    "        liste_y_test_holdout_sk.append(y_test)\n",
    "    return liste_y_pred_holdout_sk, liste_y_test_holdout_sk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R√©partition leave One Out\n",
    "y_pred_LOO_5, y_test_LOO_5 = leaveoneout(data_reduit, \"descr_grav\", 5)\n",
    "y_pred_LOO_7, y_test_LOO_7 = leaveoneout(data_reduit, \"descr_grav\", 7)\n",
    "y_pred_LOO_10, y_test_LOO_10 = leaveoneout(data_reduit, \"descr_grav\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_LOO_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Score r√©partition leave One Out\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy_LOO_5 \u001b[39m=\u001b[39m accuracy_score(y_test_LOO_5, y_pred_LOO_5)\n\u001b[0;32m      3\u001b[0m accuracy_LOO_7 \u001b[39m=\u001b[39m accuracy_score(y_test_LOO_7, y_pred_LOO_7)\n\u001b[0;32m      4\u001b[0m accuracy_LOO_10 \u001b[39m=\u001b[39m accuracy_score(y_test_LOO_10, y_pred_LOO_10)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_LOO_5' is not defined"
     ]
    }
   ],
   "source": [
    "# Score r√©partition leave One Out\n",
    "accuracy_LOO_5 = accuracy_score(y_test_LOO_5, y_pred_LOO_5)\n",
    "accuracy_LOO_7 = accuracy_score(y_test_LOO_7, y_pred_LOO_7)\n",
    "accuracy_LOO_10 = accuracy_score(y_test_LOO_10, y_pred_LOO_10)\n",
    "\n",
    "print(accuracy_LOO_5*100)\n",
    "print(accuracy_LOO_7*100)\n",
    "print(accuracy_LOO_10*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m X_train_0 \u001b[39m=\u001b[39m liste_data_holdout[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m y_test_0 \u001b[39m=\u001b[39m  liste_data_holdout[\u001b[39m0\u001b[39m][\u001b[39m3\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_test)):\n\u001b[0;32m     19\u001b[0m     y_pred_holdout_sup_norme \u001b[39m=\u001b[39m KnnClassification_distance_sup_norme(X_test\u001b[39m.\u001b[39mloc[i], y_train, X_train, \u001b[39m5\u001b[39m)\n\u001b[0;32m     20\u001b[0m     liste_y_pred_holdout_LOO_sup_norme\u001b[39m.\u001b[39mappend(y_pred_holdout_sup_norme)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#R√©partition hold out\n",
    "liste_data_holdout = []\n",
    "#data_test = data.drop(columns=[\"latitude\", \"longitude\"])\n",
    "data_test = data_reduit\n",
    "liste_data_holdout  = holdout(data_reduit,\"descr_grav\", 5, 0.8, 0.2)\n",
    "\n",
    "# Prediction holdout from scratch\n",
    "liste_y_pred_holdout_LOO_euclidienne = []\n",
    "liste_y_pred_holdout_LOO_manhattan = []\n",
    "liste_y_pred_holdout_LOO_sup_norme = []\n",
    "\n",
    "\n",
    "X_test_0 = liste_data_holdout[0][1]\n",
    "y_train_0  = liste_data_holdout[0][2]\n",
    "X_train_0 = liste_data_holdout[0][0]\n",
    "y_test_0 =  liste_data_holdout[0][3]\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_holdout_sup_norme = KnnClassification_distance_sup_norme(X_test.loc[i], y_train, X_train, 5)\n",
    "    liste_y_pred_holdout_LOO_sup_norme.append(y_pred_holdout_sup_norme)\n",
    "    y_pred_holdout_euclidienne = KnnClassification_distance_euclidienne(X_test.loc[i], y_train, X_train, 5)\n",
    "    liste_y_pred_holdout_LOO_euclidienne.append(y_pred_holdout_euclidienne)\n",
    "    y_pred_holdout_manhattan = KnnClassification_distance_manhattan(X_test.loc[i], y_train, X_train, 5)\n",
    "    liste_y_pred_holdout_LOO_manhattan.append(y_pred_holdout_manhattan)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_holdout_sup_norme = KnnClassification_distance_sup_norme(X_test.loc[i], y_train, X_train, 7)\n",
    "    liste_y_pred_holdout_LOO_sup_norme.append(y_pred_holdout_sup_norme)\n",
    "    y_pred_holdout_euclidienne = KnnClassification_distance_euclidienne(X_test.loc[i], y_train, X_train, 7)\n",
    "    liste_y_pred_holdout_LOO_euclidienne.append(y_pred_holdout_euclidienne)\n",
    "    y_pred_holdout_manhattan = KnnClassification_distance_manhattan(X_test.loc[i], y_train, X_train, 7)\n",
    "    liste_y_pred_holdout_LOO_manhattan.append(y_pred_holdout_manhattan)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    y_pred_holdout_sup_norme = KnnClassification_distance_sup_norme(X_test.loc[i], y_train, X_train, 10)\n",
    "    liste_y_pred_holdout_LOO_sup_norme.append(y_pred_holdout_sup_norme)\n",
    "    y_pred_holdout_euclidienne = KnnClassification_distance_euclidienne(X_test.loc[i], y_train, X_train, 10)\n",
    "    liste_y_pred_holdout_LOO_euclidienne.append(y_pred_holdout_euclidienne)\n",
    "    y_pred_holdout_manhattan = KnnClassification_distance_manhattan(X_test.loc[i], y_train, X_train, 10)\n",
    "    liste_y_pred_holdout_LOO_manhattan.append(y_pred_holdout_manhattan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (149622622.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Score euclidienne:\" accuracy_holdout_euclidienne*100)\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Score r√©partition leave One Out\n",
    "accuracy_holdout_euclidienne = accuracy_score(y_test_0, liste_y_pred_holdout_LOO_euclidienne)\n",
    "accuracy_holdout_manhattan = accuracy_score(y_test_0, liste_y_pred_holdout_LOO_manhattan)\n",
    "accuracy_holdout_sup_norme = accuracy_score(y_test_0, liste_y_pred_holdout_LOO_sup_norme)\n",
    "\n",
    "print(\"Score euclidienne:\" accuracy_holdout_euclidienne*100)\n",
    "print(\"Score manhattan:\" accuracy_holdout_manhattan*100)\n",
    "print(\"Score sup norme:\" accuracy_holdout_sup_norme*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score prediction holdout scikit learn\n",
    "#for i in range(len(liste_y_pred_holdout_sk)):\n",
    "liste_y_pred_holdout_sk, liste_y_test_holdout_sk = KnnClassification_sk_learn(liste_data_holdout)\n",
    "accuracy_holdout_sk = accuracy_score(liste_y_test_holdout_sk, liste_y_pred_holdout_sk)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification avec trois algo \"haut niveau\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## support vector machine (SVM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.read_csv(\"../dfClean.csv\")\n",
    "\n",
    "\n",
    "# Step 2: Sample the specified percentage of rows\n",
    "df = df.sample(frac=0.06, random_state=42)\n",
    "\n",
    "# Step 3: Store the sampled portion in a new DataFrame\n",
    "df.reset_index(drop=True, inplace=True)  # Reset index if needed\n",
    "\n",
    "\n",
    "# Step 1: Select feature columns (X) and target column (y)\n",
    "feature_columns = df.columns.drop('descr_grav')\n",
    "target_column = 'descr_grav'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1,10],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.1, 0.5, 1]\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Create an SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Step 4: Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 0.5, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 0.5, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.1, 0.5, 1],\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 5: Fit the GridSearchCV object\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Score: 0.4054902922542408\n",
      "[[372   0   0   0]\n",
      " [307   0   0   0]\n",
      " [167   0   0   0]\n",
      " [ 29   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Retrieve the best parameters and best score\n",
    "best_params_svm = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", best_params_svm)\n",
    "print(\"Best Score:\", best_score)\n",
    "ypred = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,ypred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=0.1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 7: Train a new SVM model with the best parameters\n",
    "best_svm = SVC(**best_params_svm)\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/modelSVC.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_svm,\"../models/modelSVC.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42514285714285716\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the model on the test data or perform further analysis\n",
    "accuracy = best_svm.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Step 1: Select feature columns (X) and target column (y)\n",
    "feature_columns = df.columns.drop('descr_grav')\n",
    "target_column = 'descr_grav'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)\n",
    "\n",
    "# Step 3: Define the RandomForest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Step 4: Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Step 5: Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(rf, param_grid, scoring='accuracy')\n",
    "\n",
    "# Step 6: Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Step 8: Train the RandomForest model with the best parameters\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Evaluate the model on the testing data\n",
    "accuracy = best_rf.score(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Score: 0.5959472716125076\n",
      "Accuracy: 0.6057142857142858\n",
      "[[302  59  11   0]\n",
      " [115 170  22   0]\n",
      " [ 59  61  47   0]\n",
      " [ 11   8  10   0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters, best score, and accuracy\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "best_model = grid_search.best_estimator_\n",
    "ypred = best_model.predict(X_test)\n",
    "print(confusion_matrix(y_test,ypred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
